# Introduction
This project implement classic machine learning algorithms(ML). Motivations for this project includes:
- Helping machine learning freshman have a better and deeper understanding of the basic algorithms and models in this field.
- Providing the real-life and commercial executing methods in ML filed.
- Keeping my Mathematics Theory and Coding ability fresh due to such cases. 

# Overview
### 1.FM
#### 1.1 fastfm
Show how to use the package of `fast_fm` to classify the training data directly.
#### 1.2 Fsfm
@bolg：[FM解析](http://shataowei.com/2017/12/04/FM理论解析及应用/)

We rewrite fm by ourselves and focus helping people get deeper insights about FM.So we upload it to the pypi named `Fsfm`,you can downlode it if you're interested in it.
****
### 2.N-gram
An interview problem in 'Nlp' solved by n-gram instead of Naive Bayes.
****
### 3.Svd
@bolg：[SVD解析](http://shataowei.com/2017/08/27/SVD及扩展的矩阵分解方法/)
#### 3.1 Matrix decomposition in linalg
#### 3.2 Matrix decomposition with RSVD 
****
### 4.Collaborative Filtering Recommendation System 
@bolg：[协同推荐解析](http://shataowei.com/2017/12/01/能够快速实现的协同推荐/)
#### 4.1 Base of Item
#### 4.2 Base of User
****
### 5.Semantic recognition
@bolg：[评价文本判断用户流失倾向](http://shataowei.com/2017/08/15/基于自然语言识别下的流失用户预警/)
#### 5.1 Jieba Process
#### 5.2 Tf-Idf
#### 5.3 Bp Neural Network
#### 5.4 SVM process
#### 5.5 Naive Bayes
#### 5.6 RandomForest
****
### 6.Gradient_descent
****
### 7.Smote
@bolg：[SMOTE解析](http://shataowei.com/2017/12/01/SMOTE算法/)
#### 7.1 Mean of the weight  
#### 7.2 Random scale in connected Vector
****
### 8.Frcwp
@bolg：[风控方法解析](http://shataowei.com/2017/12/09/风控用户识别方法/)

It means fast risk control with python.It's a lightweight tool that automatic recognize the outliers from a large data pool. 

****
### 9.Ensemble
@bolg:[Kaggle&TianChi分类问题相关算法快速实现
](http://shataowei.com/2017/12/28/Kaggle-TianChi分类问题相关算法快速实现/)

@bolg:[Kaggle&TianChi分类问题相关纯算法理论剖析
](http://shataowei.com/2017/12/30/Kaggle-TianChi分类问题相关纯算法理论剖析/)
#### 9.1 Data preprocessing before ensemble 
#### 9.2 Case showed by stacking xgboost and logistic regression
#### 9.3 Case showed by stacking gbdt and logistic regression
#### 9.4 Case showed by bagging xgboots or gbdts
#### 9.5 How to use the trained stacking model during the online module

****
### 10.Tsnewp
T-distributed stochastic neighbor embedding(t-SNE) rewrite with Python by ourselves, it's a good dimensionality reduction method.
Add many explanation among the code.

[Package download address](https://pypi.python.org/pypi?:action=display&name=Tsnewp&version=0.0.1).

[More test data](http://lvdmaaten.github.io/tsne/).

****
### 11.Knowledge Summary
Some question for the new hand to estimate their level of the ML、DL.What's more ,it also contains the key point which i think during my study with Andrew Ng‘s machine learning lessons（to be continued）.

Also, i write some words to the new hand. Read it []() if you're interested in it .

# Requirements
Python Environment.
More details getting from single project requirement.

# More
If you find some incorrect content, i'm so sorry about that. PLS contact me by the following way:
- WeChat:sharalion
- E-mail:stw386@sina.com
- Message Board in my [bolg](http://shataowei.com)
